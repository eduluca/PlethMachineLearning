{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plethysmography Recording Data Collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Instructions\n",
    "\n",
    "\n",
    "\n",
    "Combine all datapoints and create a single \"data_train.npy\" and \"labels_train.npy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## READING AND SEPARATING INTO DATA AND LABELS ##################################################\n",
    "\n",
    "labels_data_path_type2 = r\"C:\\Users\\aluca\\Github\\PlethMachineLearning\\Pleth_Breath_Types\\Currently_labeling_data\\balanced_labeled_dataset_type2.xlsx\"\n",
    "unseen_labels_data_path_type2 = r\"C:\\Users\\aluca\\Github\\PlethMachineLearning\\Pleth_Breath_Types\\Currently_labeling_data\\Unseen (Blinded)\\balanced_unseen_data_type2.xlsx\"\n",
    "df_type2 = pd.read_excel(labels_data_path_type2)                    #Read excel file with training data and labels\n",
    "unseen_df_type2 = pd.read_excel(unseen_labels_data_path_type2)      #Read excel file with unseen data and labels\n",
    "\n",
    "# Extract data and labels\n",
    "#data = df.iloc[:, :43].to_numpy()  # Assuming columns 0 to 42 are features\n",
    "#labels = df['labels'].to_numpy()    # Assuming 'labels' is the name of the label column\n",
    "\n",
    "# Save data and labels as NumPy files\n",
    "\n",
    "#np.save('data_train.npy', data)\n",
    "#np.save('labels_train.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 16)\n",
      "(160, 16)\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame with labeled data\n",
    "\n",
    "# Extract relevant features\n",
    "#features = df[['Sample', 'Site Time', 'Storage ID', 'First Beat ID', 'Last Beat ID', 'Ti (msec)', 'Te (msec)', 'PIF', 'PEF', 'TV', 'EV', 'RT (msec)', 'MV', 'P (msec)', 'f (bpm)', 'EIP (msec)', 'EEP (msec)', 'Penh', 'EF50', 'RH', 'Tbox', 'Tbody', 'Patm', 'VCF', 'AV', 'Sr', 'n']]\n",
    "#features_type2 = df_type2[['Ti (msec)', 'Te (msec)', 'PIF', 'PEF', 'TV', 'EV', 'RT (msec)', 'MV', 'P (msec)', 'f (bpm)', 'EIP (msec)', 'EEP (msec)', 'Penh', 'EF50', 'RH', 'Sr', 'Phase']]\n",
    "features_type2 = df_type2[['Ti (msec)', 'Te (msec)', 'PIF', 'PEF', 'TV', 'EV', 'RT (msec)', 'MV', 'P (msec)', 'f (bpm)', 'EIP (msec)', 'EEP (msec)', 'Penh', 'EF50', 'Sr', 'Phase']]\n",
    "#features2 = df2[['Ti (msec)', 'Te (msec)', 'PIF', 'PEF', 'TV', 'EV', 'RT (msec)', 'MV', 'P (msec)', 'f (bpm)', 'EIP (msec)', 'EEP (msec)', 'Penh', 'EF50', 'RH', 'Tbox', 'VCF', 'AV', 'Sr']]\n",
    "#unseen_features_type2 = unseen_df_type2[['Ti (msec)', 'Te (msec)', 'PIF', 'PEF', 'TV', 'EV', 'RT (msec)', 'MV', 'P (msec)', 'f (bpm)', 'EIP (msec)', 'EEP (msec)', 'Penh', 'EF50', 'RH', 'Tbox', 'VCF', 'AV', 'Sr']]\n",
    "unseen_features_type2 = unseen_df_type2[['Ti (msec)', 'Te (msec)', 'PIF', 'PEF', 'TV', 'EV', 'RT (msec)', 'MV', 'P (msec)', 'f (bpm)', 'EIP (msec)', 'EEP (msec)', 'Penh', 'EF50', 'Sr', 'Phase']]\n",
    "\n",
    "# Convert 'Site Time' to datetime\n",
    "#features['timestamp'] = pd.to_datetime(features['Site Time'], format='%H:%M:%S.%f')\n",
    "\n",
    "# Calculate the time difference in seconds\n",
    "#features['timestamp_seconds'] = (features['timestamp'] - features['timestamp'].min()).dt.total_seconds()\n",
    "\n",
    "# Drop the original timestamp column\n",
    "#features = features.drop(columns=['Site Time', 'timestamp'])\n",
    "\n",
    "# Standardize features\n",
    "#scaler = StandardScaler()\n",
    "#features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# Extract labels\n",
    "# BREATH TYPES: Quiet Breath (0), Sigh (1), Sniffing (2), Random Apnea (3), Apnea Type II (4)\n",
    "labels_type2 = df_type2['Labels']  \n",
    "#labels2 = df2['Labels']\n",
    "unseen_labels_type2 = unseen_df_type2['Labels'] \n",
    "\n",
    "\n",
    "# OPTION 1: use 'Unknown' for uncertain labels\n",
    "#all_data['Labels'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# OPTION 2: exclude rows where the label is uncertain\n",
    "#all_data = all_data.dropna(subset=['Breath_Type'])\n",
    "\n",
    "# Save training data and labels as NumPy files\n",
    "np.save('data_train_type2', features_type2)\n",
    "np.save('labels_train_type2', labels_type2)\n",
    "\n",
    "# Save unseen testing data and labels as NumPy files\n",
    "np.save('data_unseen_type2', unseen_features_type2)\n",
    "np.save('labels_unseen_type2', unseen_labels_type2)\n",
    "\n",
    "#np.save('napoli_data', features2)\n",
    "#np.save('napoli_labels', labels2)\n",
    "\n",
    "print(features_type2.shape)\n",
    "print(unseen_features_type2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
